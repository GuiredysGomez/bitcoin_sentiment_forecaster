{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34275ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2779afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(\"../../../data/training_set.csv\")\n",
    "validation_set = pd.read_csv(\"../../../data/validation_set.csv\")\n",
    "test_set = pd.read_csv(\"../../../data/test_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a numpy arrays\n",
    "# Omitir la columna 'date' por el formato de fecha\n",
    "x_train = training_set.drop(columns=['target_trend','date']).values\n",
    "y_train = training_set['target_trend'].values\n",
    "x_validation = validation_set.drop(columns=['target_trend','date']).values\n",
    "y_validation = validation_set['target_trend'].values\n",
    "x_test = test_set.drop(columns=['target_trend','date']).values\n",
    "y_test = test_set['target_trend'].values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Asignar las columnas de características (serie temporal)\n",
    "# x_train = training_set.iloc[:, 1:51]\n",
    "# x_validation = validation_set.iloc[:, 1:51]\n",
    "# x_test = test_set.iloc[:, 1:51]\n",
    "# # Asignar la columna objetivo (última columna)\n",
    "# y_train = training_set.iloc[:, -1]\n",
    "# y_validation = validation_set.iloc[:, -1]\n",
    "# y_test = test_set.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a DataFrame para facilitar la visualización\n",
    "train_distribution = pd.Series(y_train).value_counts(normalize=True)\n",
    "validation_distribution = pd.Series(y_validation).value_counts(normalize=True)\n",
    "test_distribution = pd.Series(y_test).value_counts(normalize=True)\n",
    "\n",
    "# Comparar visualmente\n",
    "df = pd.DataFrame({\n",
    "    'Train': train_distribution,\n",
    "    'Validation': validation_distribution,\n",
    "    'Test': test_distribution\n",
    "}).fillna(0)\n",
    "\n",
    "df.plot(kind='bar', title='Distribución de Clases')\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Proporción')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091b5c0",
   "metadata": {},
   "source": [
    "IMPORTANTE: Hay que sumar a la columna de prediccion porque -1 no funciona en funcion de LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf24a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train += 1\n",
    "y_validation += 1\n",
    "y_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d67ad8",
   "metadata": {},
   "source": [
    "Compilacion y entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setear la semilla para reproducibilidad\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# Definición de hiperparámetros\n",
    "learning_rate = 0.001\n",
    "n_l1 = 100\n",
    "n_l2 = 60\n",
    "n_l3 = 30\n",
    "n_l4 = 10\n",
    "# n_l5 = 10\n",
    "# Definición del modelo\n",
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(50,)),\n",
    "        Dense(n_l1,activation='relu',name='L1'),\n",
    "        # Dropout(0.2, name='Dropout1'),\n",
    "        Dense(n_l2,activation='relu',name='L2'),\n",
    "        # Dropout(0.2, name='Dropout2'),\n",
    "        Dense(n_l3,activation='relu',name='L3'),\n",
    "        # Dropout(0.2, name='Dropout3'),\n",
    "        Dense(n_l4,activation='relu',name='L4'),\n",
    "        # Dropout(0.2, name='Dropout4'),\n",
    "        # Dense(n_l5,activation='relu',name='L5'),\n",
    "        # Dropout(0.2, name='Dropout5'),\n",
    "        Dense(3,activation='linear',name='L6'),\n",
    "    ], name = \"softmax\" \n",
    ")\n",
    "# Compilación del modelo\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Detiene el entrenamiento si val_loss no mejora después de 10 épocas seguidas\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "# checkpoint = ModelCheckpoint(\n",
    "#     filepath='best_model.keras',\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=True\n",
    "# )\n",
    "history = model.fit(\n",
    "    x_train,y_train,\n",
    "    epochs=40,\n",
    "    validation_data=(x_validation, y_validation),\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7caa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e8b57",
   "metadata": {},
   "source": [
    "GUARDADO EN .CSV DE LOS PARAMETROS DE LOS MODELOS ENTRENADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91dc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar lista para guardar resultados\n",
    "resultados = []\n",
    "# Calcula métricas en validation\n",
    "loss, acc = model.evaluate(x_validation, y_validation, verbose=0)\n",
    "y_pred_val = np.argmax(model.predict(x_validation), axis=1)\n",
    "f1 = f1_score(y_validation, y_pred_val, average='macro')\n",
    "\n",
    "# Guarda los resultados y los hiperparámetros usados\n",
    "resultados.append({\n",
    "    'run': len(resultados)+1,\n",
    "    'val_loss': loss,\n",
    "    'val_accuracy': acc,\n",
    "    'val_f1_macro': f1,\n",
    "    'epochs': len(history.history['loss']),\n",
    "    'learning_rate': learning_rate,\n",
    "    'n_l1': n_l1,\n",
    "    'n_l2': n_l2,\n",
    "    'n_l3': n_l3,\n",
    "    'n_l4': n_l4,\n",
    "    #'n_l5': n_l5,\n",
    "    # Agregar mas parametros si es necesario\n",
    "})\n",
    "# Convierte la lista de resultados a DataFrame\n",
    "df_nuevos = pd.DataFrame(resultados)\n",
    "\n",
    "# Si el archivo ya existe, lo leemos y concatenamos\n",
    "csv_path = 'resultados_entrenamientos.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    df_existente = pd.read_csv(csv_path)\n",
    "    df_final = pd.concat([df_existente, df_nuevos], ignore_index=True)\n",
    "else:\n",
    "    df_final = df_nuevos\n",
    "\n",
    "# Guardamos el DataFrame combinado\n",
    "df_final.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9275ad",
   "metadata": {},
   "source": [
    "Grafica de Loss y Accuracy en train_set & validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e843ec",
   "metadata": {},
   "source": [
    "F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a4faaaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Validación:\n",
      "[[15 12  0]\n",
      " [ 2  4  2]\n",
      " [ 6 16 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60        27\n",
      "           1       0.12      0.50      0.20         8\n",
      "           2       0.97      0.77      0.86        95\n",
      "\n",
      "    accuracy                           0.71       130\n",
      "   macro avg       0.58      0.61      0.55       130\n",
      "weighted avg       0.85      0.71      0.76       130\n",
      "\n",
      "Test:\n",
      "[[34 17  2]\n",
      " [ 5  7  1]\n",
      " [ 2 13 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8293    0.6415    0.7234        53\n",
      "           1     0.1892    0.5385    0.2800        13\n",
      "           2     0.9434    0.7692    0.8475        65\n",
      "\n",
      "    accuracy                         0.6947       131\n",
      "   macro avg     0.6540    0.6497    0.6170       131\n",
      "weighted avg     0.8224    0.6947    0.7410       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtener predicciones\n",
    "y_pred_val = np.argmax(model.predict(x_validation), axis=1)\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "# Reporte completo: precisión, recall y F1 por clase\n",
    "print(\"Validación:\")\n",
    "print(confusion_matrix(y_validation, y_pred_val))\n",
    "print(classification_report(y_validation, y_pred_val))\n",
    "print(\"Test:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
