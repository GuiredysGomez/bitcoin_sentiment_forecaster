{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e765f08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toyotx22/bitcoin_sentiment_forecaster/tf_venv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-20 21:53:05.652769: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-20 21:53:06.034055: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-20 21:53:06.034370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-20 21:53:06.107110: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-20 21:53:06.261435: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-20 21:53:06.267319: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-20 21:53:07.859595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '1234'\n",
    "import random\n",
    "random.seed(43)\n",
    "import numpy as np\n",
    "np.random.seed(43)\n",
    "import pandas as pd\n",
    "import optuna   \n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(43)\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report,  balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "from optuna.visualization import plot_optimization_history\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34275ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 43\n",
    " # Se puede cambiar a \"precision\" o \"recall\" o \"f1-score\"\n",
    "SCORE = \"f1-score\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b22da0",
   "metadata": {},
   "source": [
    "Score Trend Changes Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2984ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_changes_score(y_test: np.array, y_pred: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the trend changes score based on the test and predicted values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (np.array): True labels.\n",
    "        y_pred (np.array): Predicted labels.\n",
    "        \n",
    "    Returns:\n",
    "        float: The trend changes score.\n",
    "    \"\"\"\n",
    "    y_df = pd.DataFrame([y_test, y_pred]).T\n",
    "    y_df.columns = [\"y_test\", \"y_pred\"]\n",
    "    y_df[\"y_test_shifted\"] = y_df[\"y_test\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_test\"] = y_df[\"y_test\"] != y_df[\"y_test_shifted\"]\n",
    "    y_df[\"y_predict_shifted\"] = y_df[\"y_pred\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_predict\"] = y_df[\"y_pred\"] != y_df[\"y_predict_shifted\"]\n",
    "    return classification_report(y_df[\"is_changed_trend_test\"][:-1], y_df[\"is_changed_trend_predict\"][:-1], digits=4)\n",
    "\n",
    "def trend_changes_true(y_test: np.array, y_pred: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the trend changes score based on the test and predicted values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (np.array): True labels.\n",
    "        y_pred (np.array): Predicted labels.\n",
    "        \n",
    "    Returns:\n",
    "        float: The trend changes score.\n",
    "    \"\"\"\n",
    "    y_df = pd.DataFrame([y_test, y_pred]).T\n",
    "    y_df.columns = [\"y_test\", \"y_pred\"]\n",
    "    y_df[\"y_test_shifted\"] = y_df[\"y_test\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_test\"] = y_df[\"y_test\"] != y_df[\"y_test_shifted\"]\n",
    "    y_df[\"y_predict_shifted\"] = y_df[\"y_pred\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_predict\"] = y_df[\"y_pred\"] != y_df[\"y_predict_shifted\"]\n",
    "    report = classification_report(\n",
    "        y_df[\"is_changed_trend_test\"][:-1],\n",
    "        y_df[\"is_changed_trend_predict\"][:-1],\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    return report[\"True\"][SCORE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "332e69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(\"../../../data/training_set.csv\", parse_dates=['date'])\n",
    "validation_set = pd.read_csv(\"../../../data/validation_set.csv\", parse_dates=['date'])\n",
    "test_set = pd.read_csv(\"../../../data/test_set.csv\", parse_dates=['date'])\n",
    "# Cargar datos\n",
    "X_train = training_set.drop(columns=['target_trend','date']).values\n",
    "y_train = training_set['target_trend'].values\n",
    "X_val = validation_set.drop(columns=['target_trend','date']).values\n",
    "y_validation = validation_set['target_trend'].values\n",
    "X_test = test_set.drop(columns=['target_trend','date']).values\n",
    "y_test = test_set['target_trend'].values    \n",
    "\n",
    "# IMPORTANTE: Hay que sumar a la columna de prediccion porque -1 no funciona en la funcion de perdida en los entrenamientos\n",
    "y_train = y_train + 1\n",
    "y_validation = y_validation + 1\n",
    "y_test = y_test + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f3d9b",
   "metadata": {},
   "source": [
    "OPTIMIZACION CON OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    # Hiperparámetros a optimizar\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    n_l1 = trial.suggest_int(\"n_l1\", 32, 256, step=32)\n",
    "    n_l2 = trial.suggest_int(\"n_l2\", 32, 256, step=32)\n",
    "    n_l3 = trial.suggest_int(\"n_l3\", 16, 128, step=16)\n",
    "    n_l4 = trial.suggest_int(\"n_l4\", 8, 64, step=8)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"selu\"])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = {\n",
    "        \"adam\": tf.keras.optimizers.Adam,\n",
    "        \"rmsprop\": tf.keras.optimizers.RMSprop,\n",
    "        \"sgd\": tf.keras.optimizers.SGD\n",
    "    }[optimizer_name](learning_rate=learning_rate)\n",
    "\n",
    "    # Modelo\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(X_train.shape[1],)),\n",
    "        Dense(n_l1, activation=activation),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(n_l2, activation=activation),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(n_l3, activation=activation),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(n_l4, activation=activation),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(3, activation='linear')  # 3 clases\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Entrenamiento\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_validation),\n",
    "        epochs=60,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predicción y evaluación con tu métrica personalizada\n",
    "    y_pred_logits = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "\n",
    "    score = trend_changes_true(y_validation, y_pred)\n",
    "    # Liberar memoria GPU y limpiar sesión\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    return score  # Este es el valor que Optuna maximiza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", \n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    ")\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el historial de optimización\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ce71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(study.best_params)\n",
    "print(f\"Mejor score de {SCORE}: {study.best_value:.4f}\")\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecd40d",
   "metadata": {},
   "source": [
    "GUARDAR EN JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df857fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los mejores hiperparámetros y su valor\n",
    "history = []\n",
    "if os.path.exists(\"best_hyperparams.json\"):\n",
    "    try:\n",
    "        with open(\"best_hyperparams.json\", \"r\") as f:\n",
    "            history = json.load(f)\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        history = []\n",
    "\n",
    "# Guardar ambos en un solo diccionario\n",
    "history.append({\n",
    "    \"params\": study.best_params,\n",
    "    \"value\": study.best_value\n",
    "})\n",
    "\n",
    "with open(\"best_hyperparams.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d24af",
   "metadata": {},
   "source": [
    "CARGAR HIPERPARAMETROS DESDE JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9bc8a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiperparámetros #1: {'learning_rate': 1.00984195139193e-05, 'n_l1': 192, 'n_l2': 128, 'n_l3': 80, 'n_l4': 32, 'dropout_rate': 0.01560157455885968, 'activation': 'selu', 'optimizer': 'rmsprop', 'batch_size': 256}, Valor: 0.5777777777777777\n",
      "Hiperparámetros #2: {'learning_rate': 1.00984195139193e-05, 'n_l1': 192, 'n_l2': 128, 'n_l3': 80, 'n_l4': 32, 'dropout_rate': 0.01560157455885968, 'activation': 'selu', 'optimizer': 'rmsprop', 'batch_size': 256}, Valor: 0.5777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Cargar historial de hiperparámetros y valores\n",
    "with open(\"best_hyperparams.json\", \"r\") as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "# Escoger el último (más reciente)\n",
    "best_params = history[-1][\"params\"]\n",
    "best_value = history[-1][\"value\"]\n",
    "\n",
    "# Si quieres ver todos:\n",
    "for i, entry in enumerate(history):\n",
    "    print(f\"Hiperparámetros #{i+1}: {entry['params']}, Valor: {entry['value']}\")\n",
    "\n",
    "# Si quieres escoger uno específico (por índice):\n",
    "# best_params = history[indice_que_quieras][\"params\"]\n",
    "# best_value = history[indice_que_quieras][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8f94fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Multiclass Neural Network Trend Changes Score:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9604    0.8661    0.9108       112\n",
      "        True     0.4643    0.7647    0.5778        17\n",
      "\n",
      "    accuracy                         0.8527       129\n",
      "   macro avg     0.7123    0.8154    0.7443       129\n",
      "weighted avg     0.8950    0.8527    0.8669       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carga de librerias con su semilla para garantizar reproducibilidad\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Modelo final con los mejores hiperparámetros\n",
    "final_optimizer = {\n",
    "    \"adam\": tf.keras.optimizers.Adam,\n",
    "    \"rmsprop\": tf.keras.optimizers.RMSprop,\n",
    "    \"sgd\": tf.keras.optimizers.SGD\n",
    "}[best_params[\"optimizer\"]](learning_rate=best_params[\"learning_rate\"])\n",
    "final_model = Sequential([\n",
    "    Dense(best_params[\"n_l1\"], activation=best_params[\"activation\"]),\n",
    "    Dropout(best_params[\"dropout_rate\"]),\n",
    "    Dense(best_params[\"n_l2\"], activation=best_params[\"activation\"]),\n",
    "    Dropout(best_params[\"dropout_rate\"]),\n",
    "    Dense(best_params[\"n_l3\"], activation=best_params[\"activation\"]),\n",
    "    Dropout(best_params[\"dropout_rate\"]),\n",
    "    Dense(best_params[\"n_l4\"], activation=best_params[\"activation\"]),\n",
    "    Dropout(best_params[\"dropout_rate\"]),\n",
    "    Dense(3, activation='linear')  # 3 clases\n",
    "])\n",
    "final_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=final_optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = final_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_validation),\n",
    "    epochs=60,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "# Obtener predicciones\n",
    "y_pred_val = np.argmax(final_model.predict(X_val), axis=1)\n",
    "print(\"Multiclass Neural Network Trend Changes Score:\\n\", trend_changes_score(y_validation, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e695829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Multiclass Neural Network Trend Changes Score:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9263    0.7395    0.8224       119\n",
      "        True     0.1143    0.3636    0.1739        11\n",
      "\n",
      "    accuracy                         0.7077       130\n",
      "   macro avg     0.5203    0.5516    0.4982       130\n",
      "weighted avg     0.8576    0.7077    0.7676       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtener predicciones\n",
    "y_pred_test = np.argmax(final_model.predict(X_test), axis=1)\n",
    "print(\"Multiclass Neural Network Trend Changes Score:\\n\", trend_changes_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561635ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 1ms/step\n",
      "Multiclass Neural Network Trend Changes Score:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.8816    0.6861    0.7717       532\n",
      "        True     0.1257    0.3288    0.1818        73\n",
      "\n",
      "    accuracy                         0.6430       605\n",
      "   macro avg     0.5036    0.5074    0.4767       605\n",
      "weighted avg     0.7904    0.6430    0.7005       605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = np.argmax(final_model.predict(X_train), axis=1)\n",
    "print(\"Multiclass Neural Network Trend Changes Score:\\n\", trend_changes_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9a5c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Neural Network Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7000    0.5833    0.6364        24\n",
      "           1     0.5294    0.5000    0.5143        18\n",
      "           2     0.9032    0.9545    0.9282        88\n",
      "\n",
      "    accuracy                         0.8231       130\n",
      "   macro avg     0.7109    0.6793    0.6929       130\n",
      "weighted avg     0.8139    0.8231    0.8170       130\n",
      "\n",
      "Balanced accuracy: 0.6792929292929294\n"
     ]
    }
   ],
   "source": [
    "# Reporte completo: precisión, recall y F1 por clase\n",
    "report = classification_report(y_validation, y_pred_val, digits=4)\n",
    "print(\"Multiclass Neural Network Report:\\n\", report)\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_validation, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d67ad8",
   "metadata": {},
   "source": [
    "Compilacion y entrenamiento de la red SIN OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98167d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de hiperparámetros\n",
    "learning_rate = 0.001\n",
    "n_l1 = 100 #100\n",
    "n_l2 = 60  #60\n",
    "n_l3 = 30  #30\n",
    "n_l4 = 10  #10\n",
    "\n",
    "# Definición del modelo\n",
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(X_train.shape[1],)),\n",
    "        Dense(n_l1,activation='relu',name='L1'),\n",
    "        Dense(n_l2,activation='relu',name='L2'),\n",
    "        Dense(n_l3,activation='relu',name='L3'),\n",
    "        Dense(n_l4,activation='relu',name='L4'),\n",
    "        Dense(3,activation='linear',name='L5'),\n",
    "    ], name = \"multiclass\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7caa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Detiene el entrenamiento si val_loss no mejora después de 10 épocas seguidas\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "# checkpoint = ModelCheckpoint(\n",
    "#     filepath='best_model.keras',\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=True\n",
    "# )\n",
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=60,\n",
    "    validation_data=(X_val, y_validation),\n",
    "    callbacks=[early_stop], \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9275ad",
   "metadata": {},
   "source": [
    "Grafica de Loss y Accuracy en train_set & validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e843ec",
   "metadata": {},
   "source": [
    "F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4faaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener predicciones\n",
    "y_pred_val = np.argmax(model.predict(X_val), axis=1)\n",
    "# Reporte completo: precisión, recall y F1 por clase\n",
    "report = classification_report(y_validation, y_pred_val, digits=4)\n",
    "print(\"Multiclass Neural Network Report:\\n\", report)\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_validation, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80511373",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multiclass Neural Network trend_changes_score:\\n\",\n",
    "    trend_changes_score(y_validation, y_pred_val)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_venv2 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
