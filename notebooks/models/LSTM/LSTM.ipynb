{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77abc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8995ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Seeds =========\n",
    "SEED = 43\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcda7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE = \"f1-score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a14e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend_changes_report_dict(y_test: np.array, y_pred: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the trend changes score based on the test and predicted values.\n",
    "    \n",
    "    Args:\n",
    "        y_test (np.array): True labels.\n",
    "        y_pred (np.array): Predicted labels.\n",
    "        \n",
    "    Returns:\n",
    "        float: The trend changes score.\n",
    "    \"\"\"\n",
    "    y_df = pd.DataFrame([y_test, y_pred]).T\n",
    "    y_df.columns = [\"y_test\", \"y_pred\"]\n",
    "    y_df[\"y_test_shifted\"] = y_df[\"y_test\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_test\"] = y_df[\"y_test\"] != y_df[\"y_test_shifted\"]\n",
    "    y_df[\"y_predict_shifted\"] = y_df[\"y_pred\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_predict\"] = y_df[\"y_pred\"] != y_df[\"y_predict_shifted\"]\n",
    "    return classification_report(\n",
    "        y_df[\"is_changed_trend_test\"][:-1], \n",
    "        y_df[\"is_changed_trend_predict\"][:-1], \n",
    "        digits=4,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "def trend_changes_score(y_test: np.array, y_pred: np.array) -> str:\n",
    "    y_df = pd.DataFrame([y_test, y_pred]).T\n",
    "    y_df.columns = [\"y_test\", \"y_pred\"]\n",
    "    y_df[\"y_test_shifted\"] = y_df[\"y_test\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_test\"] = y_df[\"y_test\"] != y_df[\"y_test_shifted\"]\n",
    "    y_df[\"y_predict_shifted\"] = y_df[\"y_pred\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_predict\"] = y_df[\"y_pred\"] != y_df[\"y_predict_shifted\"]\n",
    "    return classification_report(\n",
    "        y_df[\"is_changed_trend_test\"][:-1],\n",
    "        y_df[\"is_changed_trend_predict\"][:-1],\n",
    "        digits=4\n",
    "    )\n",
    "\n",
    "def trend_changes_true(y_test: np.array, y_pred: np.array) -> float:\n",
    "    y_df = pd.DataFrame([y_test, y_pred]).T\n",
    "    y_df.columns = [\"y_test\", \"y_pred\"]\n",
    "    y_df[\"y_test_shifted\"] = y_df[\"y_test\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_test\"] = y_df[\"y_test\"] != y_df[\"y_test_shifted\"]\n",
    "    y_df[\"y_predict_shifted\"] = y_df[\"y_pred\"].shift(-1)\n",
    "    y_df[\"is_changed_trend_predict\"] = y_df[\"y_pred\"] != y_df[\"y_predict_shifted\"]\n",
    "    report = classification_report(\n",
    "        y_df[\"is_changed_trend_test\"][:-1],\n",
    "        y_df[\"is_changed_trend_predict\"][:-1],\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    return report[\"True\"][SCORE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56805697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 16:12:18,872] A new study created in memory with name: no-name-14e3122f-6c14-40ae-ac79-d5f81185a0bb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1374, 5, 12) (samples, timesteps, features)\n",
      "X_val:   (294, 5, 12)\n",
      "X_test:  (295, 5, 12)\n",
      "Timesteps=5, Features/step=12 -> steps=[-4, -3, -2, -1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-24 16:12:32,053] Trial 0 finished with value: 0.32 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 32, 'dropout': 0.12029480998267439, 'learning_rate': 0.00045110548904864363, 'optimizer': 'adam', 'batch_size': 128, 'patience': 11}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:12:44,570] Trial 1 finished with value: 0.26666666666666666 and parameters: {'lstm_layers': 2, 'units1': 96, 'units2': 32, 'dense_units': 112, 'dropout': 0.11051449794218565, 'learning_rate': 0.0006456228551735266, 'optimizer': 'adam', 'batch_size': 128, 'patience': 11}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:12:58,215] Trial 2 finished with value: 0.2807017543859649 and parameters: {'lstm_layers': 2, 'units1': 128, 'units2': 192, 'dense_units': 16, 'dropout': 0.44854928999076715, 'learning_rate': 0.00039446366127822994, 'optimizer': 'adam', 'batch_size': 128, 'patience': 15}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:13:18,993] Trial 3 finished with value: 0.0 and parameters: {'lstm_layers': 2, 'units1': 256, 'units2': 160, 'dense_units': 16, 'dropout': 0.0904572976289505, 'learning_rate': 0.008055276308256441, 'optimizer': 'rmsprop', 'batch_size': 32, 'patience': 15}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:13:27,719] Trial 4 finished with value: 0.0 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 128, 'dropout': 0.36786354075356037, 'learning_rate': 0.0007764666819777239, 'optimizer': 'adam', 'batch_size': 32, 'patience': 13}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:13:54,804] Trial 5 finished with value: 0.2631578947368421 and parameters: {'lstm_layers': 2, 'units1': 160, 'units2': 64, 'dense_units': 32, 'dropout': 0.3978694324080221, 'learning_rate': 0.00038077248258733476, 'optimizer': 'adam', 'batch_size': 64, 'patience': 9}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:14:31,190] Trial 6 finished with value: 0.24324324324324326 and parameters: {'lstm_layers': 2, 'units1': 64, 'units2': 192, 'dense_units': 96, 'dropout': 0.34763043347754646, 'learning_rate': 0.00016050388801978855, 'optimizer': 'adam', 'batch_size': 32, 'patience': 15}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:14:40,965] Trial 7 finished with value: 0.3076923076923077 and parameters: {'lstm_layers': 2, 'units1': 32, 'units2': 128, 'dense_units': 48, 'dropout': 0.03186028415865727, 'learning_rate': 0.0013779986683544274, 'optimizer': 'rmsprop', 'batch_size': 128, 'patience': 13}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:14:54,074] Trial 8 finished with value: 0.3116883116883117 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 128, 'dropout': 0.12752314016739824, 'learning_rate': 0.0007702387955222299, 'optimizer': 'adam', 'batch_size': 32, 'patience': 14}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:15:28,780] Trial 9 finished with value: 0.14545454545454545 and parameters: {'lstm_layers': 2, 'units1': 256, 'units2': 224, 'dense_units': 32, 'dropout': 0.4524855903166253, 'learning_rate': 0.0012721206252753051, 'optimizer': 'rmsprop', 'batch_size': 32, 'patience': 11}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:15:43,972] Trial 10 finished with value: 0.2765957446808511 and parameters: {'lstm_layers': 1, 'units1': 192, 'dense_units': 64, 'dropout': 0.22458235485228056, 'learning_rate': 0.00011172674805909756, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 8}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:15:48,328] Trial 11 finished with value: 0.0 and parameters: {'lstm_layers': 1, 'units1': 192, 'dense_units': 80, 'dropout': 0.20267530033835235, 'learning_rate': 0.00417123953147013, 'optimizer': 'adam', 'batch_size': 128, 'patience': 13}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:15:55,882] Trial 12 finished with value: 0.0 and parameters: {'lstm_layers': 1, 'units1': 192, 'dense_units': 128, 'dropout': 0.14291501309560212, 'learning_rate': 0.0024541942033720733, 'optimizer': 'adam', 'batch_size': 128, 'patience': 10}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:16:11,732] Trial 13 finished with value: 0.2222222222222222 and parameters: {'lstm_layers': 1, 'units1': 96, 'dense_units': 80, 'dropout': 0.031571068302867156, 'learning_rate': 0.0002125704999715119, 'optimizer': 'adam', 'batch_size': 32, 'patience': 12}. Best is trial 0 with value: 0.32.\n",
      "[I 2025-08-24 16:16:19,345] Trial 14 finished with value: 0.3333333333333333 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 64, 'dropout': 0.2953561306096665, 'learning_rate': 0.0003577424015625313, 'optimizer': 'adam', 'batch_size': 64, 'patience': 12}. Best is trial 14 with value: 0.3333333333333333.\n",
      "[I 2025-08-24 16:16:37,608] Trial 15 finished with value: 0.18666666666666668 and parameters: {'lstm_layers': 1, 'units1': 224, 'dense_units': 48, 'dropout': 0.3010278233910517, 'learning_rate': 0.0003392102806728788, 'optimizer': 'adam', 'batch_size': 64, 'patience': 10}. Best is trial 14 with value: 0.3333333333333333.\n",
      "[I 2025-08-24 16:16:47,512] Trial 16 finished with value: 0.32098765432098764 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 64, 'dropout': 0.2670479835652049, 'learning_rate': 0.00028693278501454273, 'optimizer': 'adam', 'batch_size': 64, 'patience': 12}. Best is trial 14 with value: 0.3333333333333333.\n",
      "[I 2025-08-24 16:17:09,374] Trial 17 finished with value: 0.32098765432098764 and parameters: {'lstm_layers': 1, 'units1': 224, 'dense_units': 64, 'dropout': 0.2914263351224869, 'learning_rate': 0.00021206285985729092, 'optimizer': 'adam', 'batch_size': 64, 'patience': 12}. Best is trial 14 with value: 0.3333333333333333.\n",
      "[I 2025-08-24 16:17:20,941] Trial 18 finished with value: 0.2765957446808511 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 96, 'dropout': 0.27356483447025715, 'learning_rate': 0.000244206081010467, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 12}. Best is trial 14 with value: 0.3333333333333333.\n",
      "[I 2025-08-24 16:17:36,569] Trial 19 finished with value: 0.4 and parameters: {'lstm_layers': 1, 'units1': 96, 'dense_units': 48, 'dropout': 0.2063669781305509, 'learning_rate': 0.00012639285938761204, 'optimizer': 'adam', 'batch_size': 64, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:17:47,269] Trial 20 finished with value: 0.30612244897959184 and parameters: {'lstm_layers': 1, 'units1': 64, 'dense_units': 48, 'dropout': 0.19068125996553595, 'learning_rate': 0.0001294552253597395, 'optimizer': 'adam', 'batch_size': 64, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:18:02,545] Trial 21 finished with value: 0.32 and parameters: {'lstm_layers': 1, 'units1': 96, 'dense_units': 64, 'dropout': 0.24579139198479732, 'learning_rate': 0.00024424894601208407, 'optimizer': 'adam', 'batch_size': 64, 'patience': 11}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:18:12,936] Trial 22 finished with value: 0.22857142857142856 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 80, 'dropout': 0.3208070129118571, 'learning_rate': 0.0001576944694672091, 'optimizer': 'adam', 'batch_size': 64, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:18:23,103] Trial 23 finished with value: 0.25806451612903225 and parameters: {'lstm_layers': 1, 'units1': 64, 'dense_units': 48, 'dropout': 0.1720878614924661, 'learning_rate': 0.0005346251193225837, 'optimizer': 'adam', 'batch_size': 64, 'patience': 13}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:18:42,996] Trial 24 finished with value: 0.3838383838383838 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 64, 'dropout': 0.2544150029893579, 'learning_rate': 0.00010162083338203097, 'optimizer': 'adam', 'batch_size': 64, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:18:51,971] Trial 25 finished with value: 0.24390243902439024 and parameters: {'lstm_layers': 1, 'units1': 96, 'dense_units': 96, 'dropout': 0.3970665665716412, 'learning_rate': 0.0001040248610410113, 'optimizer': 'adam', 'batch_size': 64, 'patience': 8}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:19:04,079] Trial 26 finished with value: 0.37735849056603776 and parameters: {'lstm_layers': 1, 'units1': 192, 'dense_units': 48, 'dropout': 0.21622708232412802, 'learning_rate': 0.0001732831726738822, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:19:26,090] Trial 27 finished with value: 0.2828282828282828 and parameters: {'lstm_layers': 1, 'units1': 224, 'dense_units': 32, 'dropout': 0.23104982186978554, 'learning_rate': 0.0001590294759230145, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:19:42,285] Trial 28 finished with value: 0.26666666666666666 and parameters: {'lstm_layers': 1, 'units1': 192, 'dense_units': 48, 'dropout': 0.1667229347474773, 'learning_rate': 0.00010280250306078172, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:19:58,026] Trial 29 finished with value: 0.3010752688172043 and parameters: {'lstm_layers': 1, 'units1': 192, 'dense_units': 32, 'dropout': 0.07622028227624489, 'learning_rate': 0.00017316256211066415, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:20:10,116] Trial 30 finished with value: 0.0 and parameters: {'lstm_layers': 1, 'units1': 32, 'dense_units': 16, 'dropout': 0.49829190993093764, 'learning_rate': 0.00014903672097300364, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 8}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:20:18,090] Trial 31 finished with value: 0.14285714285714285 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 64, 'dropout': 0.21584757202156252, 'learning_rate': 0.0005003849538680411, 'optimizer': 'adam', 'batch_size': 64, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:20:34,404] Trial 32 finished with value: 0.2571428571428571 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 48, 'dropout': 0.3260059187074285, 'learning_rate': 0.00020393894212441963, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:20:43,750] Trial 33 finished with value: 0.379746835443038 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 80, 'dropout': 0.25797519253704193, 'learning_rate': 0.0002934922574300141, 'optimizer': 'adam', 'batch_size': 64, 'patience': 11}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:21:03,482] Trial 34 finished with value: 0.3368421052631579 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 80, 'dropout': 0.2523574042113145, 'learning_rate': 0.00012773830333207784, 'optimizer': 'adam', 'batch_size': 64, 'patience': 11}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:21:13,703] Trial 35 finished with value: 0.39215686274509803 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 112, 'dropout': 0.25623233791543426, 'learning_rate': 0.00025619832693734315, 'optimizer': 'rmsprop', 'batch_size': 128, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:21:23,576] Trial 36 finished with value: 0.25742574257425743 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 112, 'dropout': 0.16548805696930743, 'learning_rate': 0.0002753002102135349, 'optimizer': 'adam', 'batch_size': 128, 'patience': 11}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:21:36,413] Trial 37 finished with value: 0.1686746987951807 and parameters: {'lstm_layers': 2, 'units1': 96, 'units2': 256, 'dense_units': 112, 'dropout': 0.25911756295637367, 'learning_rate': 0.0006428131127366922, 'optimizer': 'adam', 'batch_size': 128, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:21:45,563] Trial 38 finished with value: 0.32432432432432434 and parameters: {'lstm_layers': 1, 'units1': 64, 'dense_units': 112, 'dropout': 0.3698527527664093, 'learning_rate': 0.0003068824159191226, 'optimizer': 'adam', 'batch_size': 128, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:21:55,249] Trial 39 finished with value: 0.0 and parameters: {'lstm_layers': 2, 'units1': 128, 'units2': 96, 'dense_units': 96, 'dropout': 0.09006636590870606, 'learning_rate': 0.009059431262375708, 'optimizer': 'rmsprop', 'batch_size': 128, 'patience': 11}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:22:03,091] Trial 40 finished with value: 0.2708333333333333 and parameters: {'lstm_layers': 1, 'units1': 96, 'dense_units': 96, 'dropout': 0.1889544272652824, 'learning_rate': 0.0008959874804877895, 'optimizer': 'adam', 'batch_size': 128, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:22:12,850] Trial 41 finished with value: 0.34408602150537637 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 48, 'dropout': 0.22642264044958793, 'learning_rate': 0.0001880170492050572, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 8}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:22:40,966] Trial 42 finished with value: 0.3132530120481928 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 16, 'dropout': 0.27967516425151234, 'learning_rate': 0.00013432857786342125, 'optimizer': 'rmsprop', 'batch_size': 32, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:22:50,977] Trial 43 finished with value: 0.30985915492957744 and parameters: {'lstm_layers': 1, 'units1': 128, 'dense_units': 32, 'dropout': 0.3210544108279817, 'learning_rate': 0.0004395696987007404, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:23:02,113] Trial 44 finished with value: 0.3655913978494624 and parameters: {'lstm_layers': 1, 'units1': 96, 'dense_units': 80, 'dropout': 0.14471975184513086, 'learning_rate': 0.00012652534783645595, 'optimizer': 'rmsprop', 'batch_size': 128, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:23:19,613] Trial 45 finished with value: 0.2716049382716049 and parameters: {'lstm_layers': 1, 'units1': 192, 'dense_units': 64, 'dropout': 0.23986545782103524, 'learning_rate': 0.00010229649463812744, 'optimizer': 'rmsprop', 'batch_size': 32, 'patience': 10}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:23:35,997] Trial 46 finished with value: 0.2564102564102564 and parameters: {'lstm_layers': 2, 'units1': 128, 'units2': 32, 'dense_units': 48, 'dropout': 0.20315579273766723, 'learning_rate': 0.001276102698270287, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 11}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:23:39,124] Trial 47 finished with value: 0.0 and parameters: {'lstm_layers': 1, 'units1': 160, 'dense_units': 128, 'dropout': 0.11758502335529412, 'learning_rate': 0.005041956112241387, 'optimizer': 'adam', 'batch_size': 128, 'patience': 9}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:23:52,871] Trial 48 finished with value: 0.32432432432432434 and parameters: {'lstm_layers': 1, 'units1': 224, 'dense_units': 112, 'dropout': 0.2096428596699289, 'learning_rate': 0.0002522973184489239, 'optimizer': 'rmsprop', 'batch_size': 64, 'patience': 8}. Best is trial 19 with value: 0.4.\n",
      "[I 2025-08-24 16:24:07,049] Trial 49 finished with value: 0.40476190476190477 and parameters: {'lstm_layers': 1, 'units1': 96, 'dense_units': 64, 'dropout': 0.3410036528275316, 'learning_rate': 0.00039871098655766774, 'optimizer': 'adam', 'batch_size': 32, 'patience': 10}. Best is trial 49 with value: 0.40476190476190477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'lstm_layers': 1, 'units1': 96, 'dense_units': 64, 'dropout': 0.3410036528275316, 'learning_rate': 0.00039871098655766774, 'optimizer': 'adam', 'batch_size': 32, 'patience': 10}\n",
      "Mejor score f1-score: 0.4048\n"
     ]
    }
   ],
   "source": [
    "# ========= Utils: reconstituir secuencias (d-4..d0) =========\n",
    "step_pat = re.compile(r\"_d(-?\\d+)$\")\n",
    "\n",
    "def infer_steps_and_bases(df_cols):\n",
    "    # Extrae steps únicos y ordenados y el orden de features base usando el step más antiguo\n",
    "    steps = sorted({int(step_pat.search(c).group(1)) for c in df_cols if step_pat.search(c)})\n",
    "    oldest = steps[0]\n",
    "    bases_oldest = [c.split(f\"_d{oldest}\")[0] for c in df_cols if c.endswith(f\"_d{oldest}\")]\n",
    "    return steps, bases_oldest\n",
    "\n",
    "def reindex_sequence_columns(df):\n",
    "    cols = [c for c in df.columns if c not in (\"date\", \"target_trend\")]\n",
    "    steps, bases = infer_steps_and_bases(df.columns)\n",
    "    ordered = []\n",
    "    for st in steps:  # mantiene orden temporal: antiguo -> reciente\n",
    "        for b in bases:\n",
    "            name = f\"{b}_d{st}\"\n",
    "            if name not in df.columns:\n",
    "                raise ValueError(f\"Falta columna esperada: {name}\")\n",
    "            ordered.append(name)\n",
    "    return ordered, steps, bases\n",
    "\n",
    "def to_sequence_array(df):\n",
    "    ordered_cols, steps, bases = reindex_sequence_columns(df)\n",
    "    X_flat = df[ordered_cols].values.astype(np.float32)\n",
    "    n, nflat = X_flat.shape\n",
    "    T = len(steps)\n",
    "    F = len(bases)\n",
    "    assert nflat == T * F, f\"Esperado {T*F} columnas, recibido {nflat}\"\n",
    "    X = X_flat.reshape(n, T, F)\n",
    "    return X, steps, bases\n",
    "\n",
    "# ========= Carga de datos =========\n",
    "DATA_DIR = \"../../../data/post_cleaning\"\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"training_set.csv\"), parse_dates=[\"date\"])\n",
    "val_df   = pd.read_csv(os.path.join(DATA_DIR, \"validation_set.csv\"), parse_dates=[\"date\"])\n",
    "test_df  = pd.read_csv(os.path.join(DATA_DIR, \"test_set.csv\"), parse_dates=[\"date\"])\n",
    "\n",
    "# Entradas (3D) y etiquetas (+1 para {0,1,2})\n",
    "X_train, steps, bases = to_sequence_array(train_df)\n",
    "X_val, _, _ = to_sequence_array(val_df)\n",
    "X_test, _, _ = to_sequence_array(test_df)\n",
    "\n",
    "y_train = (train_df[\"target_trend\"].values + 1).astype(np.int32)\n",
    "y_val   = (val_df[\"target_trend\"].values + 1).astype(np.int32)\n",
    "y_test  = (test_df[\"target_trend\"].values + 1).astype(np.int32)\n",
    "\n",
    "print(f\"X_train: {X_train.shape} (samples, timesteps, features)\")\n",
    "print(f\"X_val:   {X_val.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}\")\n",
    "print(f\"Timesteps={len(steps)}, Features/step={len(bases)} -> steps={steps}\")\n",
    "\n",
    "# ========= Definición de modelo =========\n",
    "def build_model(trial, timesteps, features):\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 2)\n",
    "    units1 = trial.suggest_int(\"units1\", 32, 256, step=32)\n",
    "    units2 = trial.suggest_int(\"units2\", 32, 256, step=32) if lstm_layers == 2 else None\n",
    "    dense_units = trial.suggest_int(\"dense_units\", 16, 128, step=16)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\"])\n",
    "    optimizer = {\"adam\": tf.keras.optimizers.Adam,\n",
    "                 \"rmsprop\": tf.keras.optimizers.RMSprop}[optimizer_name](learning_rate=learning_rate)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(timesteps, features)))\n",
    "    if lstm_layers == 2:\n",
    "        model.add(LSTM(units1, return_sequences=True, dropout=dropout))\n",
    "        model.add(LSTM(units2, dropout=dropout))\n",
    "    else:\n",
    "        model.add(LSTM(units1, dropout=dropout))\n",
    "\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(dense_units, activation=\"relu\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(3, activation=\"linear\"))  # logits\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ========= Objetivo Optuna =========\n",
    "def objective(trial):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = build_model(trial, X_train.shape[1], X_train.shape[2])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    patience = trial.suggest_int(\"patience\", 8, 15)\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=patience, restore_best_weights=True, verbose=0)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=80,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predicción y métrica personalizada\n",
    "    val_logits = model.predict(X_val, verbose=0)\n",
    "    y_val_pred = np.argmax(val_logits, axis=1)\n",
    "    score = trend_changes_true(y_val, y_val_pred)\n",
    "\n",
    "    # Limpieza\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    return score\n",
    "\n",
    "# ========= Ejecutar Optuna =========\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(\"Mejores hiperparámetros:\", study.best_params)\n",
    "print(f\"Mejor score {SCORE}: {study.best_value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26b5c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "43/43 [==============================] - 3s 19ms/step - loss: 1.1843 - accuracy: 0.3421 - val_loss: 1.0938 - val_accuracy: 0.1905\n",
      "Epoch 2/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.1203 - accuracy: 0.3792 - val_loss: 1.0184 - val_accuracy: 0.4626\n",
      "Epoch 3/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.1167 - accuracy: 0.3806 - val_loss: 1.0580 - val_accuracy: 0.4558\n",
      "Epoch 4/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0983 - accuracy: 0.4025 - val_loss: 1.0576 - val_accuracy: 0.2789\n",
      "Epoch 5/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0890 - accuracy: 0.4134 - val_loss: 0.9650 - val_accuracy: 0.5782\n",
      "Epoch 6/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0888 - accuracy: 0.3959 - val_loss: 0.9905 - val_accuracy: 0.5034\n",
      "Epoch 7/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0893 - accuracy: 0.4265 - val_loss: 0.9843 - val_accuracy: 0.5782\n",
      "Epoch 8/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0687 - accuracy: 0.4170 - val_loss: 0.9502 - val_accuracy: 0.7517\n",
      "Epoch 9/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0599 - accuracy: 0.4389 - val_loss: 0.9622 - val_accuracy: 0.5884\n",
      "Epoch 10/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0884 - accuracy: 0.4025 - val_loss: 1.0266 - val_accuracy: 0.6599\n",
      "Epoch 11/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0918 - accuracy: 0.4039 - val_loss: 1.0399 - val_accuracy: 0.6088\n",
      "Epoch 12/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0803 - accuracy: 0.4112 - val_loss: 1.0518 - val_accuracy: 0.5442\n",
      "Epoch 13/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0666 - accuracy: 0.4185 - val_loss: 1.0285 - val_accuracy: 0.5952\n",
      "Epoch 14/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0710 - accuracy: 0.4330 - val_loss: 0.9438 - val_accuracy: 0.7585\n",
      "Epoch 15/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0564 - accuracy: 0.4352 - val_loss: 1.0692 - val_accuracy: 0.4694\n",
      "Epoch 16/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0808 - accuracy: 0.4076 - val_loss: 1.0582 - val_accuracy: 0.5068\n",
      "Epoch 17/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0650 - accuracy: 0.4250 - val_loss: 0.9816 - val_accuracy: 0.7007\n",
      "Epoch 18/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0568 - accuracy: 0.4185 - val_loss: 0.9026 - val_accuracy: 0.7653\n",
      "Epoch 19/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0418 - accuracy: 0.4549 - val_loss: 0.8855 - val_accuracy: 0.7551\n",
      "Epoch 20/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0396 - accuracy: 0.4396 - val_loss: 0.9007 - val_accuracy: 0.7041\n",
      "Epoch 21/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0318 - accuracy: 0.4585 - val_loss: 0.9611 - val_accuracy: 0.6973\n",
      "Epoch 22/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0559 - accuracy: 0.4498 - val_loss: 0.9408 - val_accuracy: 0.6871\n",
      "Epoch 23/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0428 - accuracy: 0.4469 - val_loss: 0.8902 - val_accuracy: 0.7007\n",
      "Epoch 24/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0449 - accuracy: 0.4338 - val_loss: 1.0036 - val_accuracy: 0.3980\n",
      "Epoch 25/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0556 - accuracy: 0.4367 - val_loss: 0.8887 - val_accuracy: 0.7721\n",
      "Epoch 26/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0468 - accuracy: 0.4469 - val_loss: 0.8971 - val_accuracy: 0.7041\n",
      "Epoch 27/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0353 - accuracy: 0.4461 - val_loss: 0.8381 - val_accuracy: 0.7653\n",
      "Epoch 28/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0381 - accuracy: 0.4556 - val_loss: 0.8509 - val_accuracy: 0.7449\n",
      "Epoch 29/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0376 - accuracy: 0.4454 - val_loss: 0.7951 - val_accuracy: 0.7483\n",
      "Epoch 30/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0489 - accuracy: 0.4592 - val_loss: 0.8707 - val_accuracy: 0.7551\n",
      "Epoch 31/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0391 - accuracy: 0.4403 - val_loss: 0.8760 - val_accuracy: 0.6565\n",
      "Epoch 32/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0214 - accuracy: 0.4803 - val_loss: 0.8624 - val_accuracy: 0.6463\n",
      "Epoch 33/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0289 - accuracy: 0.4665 - val_loss: 0.8237 - val_accuracy: 0.7789\n",
      "Epoch 34/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0276 - accuracy: 0.4767 - val_loss: 0.9623 - val_accuracy: 0.5748\n",
      "Epoch 35/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0360 - accuracy: 0.4549 - val_loss: 0.8801 - val_accuracy: 0.6259\n",
      "Epoch 36/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0367 - accuracy: 0.4425 - val_loss: 0.7829 - val_accuracy: 0.7721\n",
      "Epoch 37/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0227 - accuracy: 0.4541 - val_loss: 0.8417 - val_accuracy: 0.7687\n",
      "Epoch 38/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0344 - accuracy: 0.4440 - val_loss: 0.8440 - val_accuracy: 0.7891\n",
      "Epoch 39/120\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 1.0687 - accuracy: 0.4418 - val_loss: 0.9614 - val_accuracy: 0.5578\n",
      "Epoch 40/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0222 - accuracy: 0.4585 - val_loss: 0.8231 - val_accuracy: 0.7619\n",
      "Epoch 41/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0115 - accuracy: 0.4716 - val_loss: 0.8137 - val_accuracy: 0.7789\n",
      "Epoch 42/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0200 - accuracy: 0.4607 - val_loss: 0.8557 - val_accuracy: 0.7789\n",
      "Epoch 43/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0334 - accuracy: 0.4491 - val_loss: 0.9214 - val_accuracy: 0.5782\n",
      "Epoch 44/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0381 - accuracy: 0.4512 - val_loss: 0.8449 - val_accuracy: 0.7755\n",
      "Epoch 45/120\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0430 - accuracy: 0.4410 - val_loss: 0.9382 - val_accuracy: 0.5544\n",
      "Epoch 46/120\n",
      "36/43 [========================>.....] - ETA: 0s - loss: 1.0252 - accuracy: 0.4653Restoring model weights from the end of the best epoch: 36.\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0229 - accuracy: 0.4702 - val_loss: 0.8356 - val_accuracy: 0.7143\n",
      "Epoch 46: early stopping\n",
      "\n",
      "LSTM Trend Changes (Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9016    0.8494    0.8748       259\n",
      "        True     0.2041    0.2941    0.2410        34\n",
      "\n",
      "    accuracy                         0.7850       293\n",
      "   macro avg     0.5529    0.5718    0.5579       293\n",
      "weighted avg     0.8207    0.7850    0.8012       293\n",
      "\n",
      "Balanced accuracy (val): 0.5933137071234221\n",
      "Classification report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7714    0.8617    0.8141        94\n",
      "           1     0.0000    0.0000    0.0000        41\n",
      "           2     0.7725    0.9182    0.8391       159\n",
      "\n",
      "    accuracy                         0.7721       294\n",
      "   macro avg     0.5146    0.5933    0.5511       294\n",
      "weighted avg     0.6644    0.7721    0.7141       294\n",
      "\n",
      "\n",
      "LSTM Trend Changes (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9184    0.8555    0.8858       263\n",
      "        True     0.2245    0.3548    0.2750        31\n",
      "\n",
      "    accuracy                         0.8027       294\n",
      "   macro avg     0.5714    0.6052    0.5804       294\n",
      "weighted avg     0.8452    0.8027    0.8214       294\n",
      "\n",
      "Balanced accuracy (test): 0.5841125229761048\n",
      "Classification report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7193    0.8454    0.7773        97\n",
      "           1     0.0000    0.0000    0.0000        26\n",
      "           2     0.8619    0.9070    0.8839       172\n",
      "\n",
      "    accuracy                         0.8068       295\n",
      "   macro avg     0.5271    0.5841    0.5537       295\n",
      "weighted avg     0.7390    0.8068    0.7709       295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toyotx22/bitcoin_sentiment_forecaster/tf_venv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/toyotx22/bitcoin_sentiment_forecaster/tf_venv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/toyotx22/bitcoin_sentiment_forecaster/tf_venv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/toyotx22/bitcoin_sentiment_forecaster/tf_venv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/toyotx22/bitcoin_sentiment_forecaster/tf_venv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/toyotx22/bitcoin_sentiment_forecaster/tf_venv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Trend Changes (Train):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9011    0.8671    0.8838      1219\n",
      "        True     0.1900    0.2468    0.2147       154\n",
      "\n",
      "    accuracy                         0.7975      1373\n",
      "   macro avg     0.5456    0.5569    0.5492      1373\n",
      "weighted avg     0.8213    0.7975    0.8087      1373\n",
      "\n",
      "Balanced accuracy (train): 0.6018199889428474\n",
      "\n",
      "Modelo guardado en lstm_best_model.keras\n"
     ]
    }
   ],
   "source": [
    "# ========= Entrenamiento final con mejores HP =========\n",
    "best = study.best_params\n",
    "final_model = build_model(\n",
    "    trial=optuna.trial.FixedTrial(best),\n",
    "    timesteps=X_train.shape[1],\n",
    "    features=X_train.shape[2]\n",
    ")\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=best.get(\"patience\", 10), restore_best_weights=True, verbose=1)\n",
    "\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=120,\n",
    "    batch_size=best.get(\"batch_size\", 64),\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ========= Evaluación =========\n",
    "# Validation\n",
    "val_logits = final_model.predict(X_val, verbose=0)\n",
    "y_val_pred = np.argmax(val_logits, axis=1)\n",
    "print(\"\\nLSTM Trend Changes (Validation):\\n\", trend_changes_score(y_val, y_val_pred))\n",
    "print(\"Balanced accuracy (val):\", balanced_accuracy_score(y_val, y_val_pred))\n",
    "print(\"Classification report (val):\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
    "\n",
    "# Test\n",
    "test_logits = final_model.predict(X_test, verbose=0)\n",
    "y_test_pred = np.argmax(test_logits, axis=1)\n",
    "print(\"\\nLSTM Trend Changes (Test):\\n\", trend_changes_score(y_test, y_test_pred))\n",
    "print(\"Balanced accuracy (test):\", balanced_accuracy_score(y_test, y_test_pred))\n",
    "print(\"Classification report (test):\\n\", classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "# Train\n",
    "train_logits = final_model.predict(X_train, verbose=0)\n",
    "y_train_pred = np.argmax(train_logits, axis=1)\n",
    "print(\"\\nLSTM Trend Changes (Train):\\n\", trend_changes_score(y_train, y_train_pred))\n",
    "print(\"Balanced accuracy (train):\", balanced_accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# ========= Guardar modelo =========\n",
    "final_model.save(\"lstm_best_model.keras\")\n",
    "print(\"\\nModelo guardado en lstm_best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Exportar y Comparar Métricas de Modelos (Validación) ---\n",
    "\n",
    "# # 1. Definir el nombre del modelo actual y el archivo de salida\n",
    "# model_name = 'LSTM'\n",
    "# output_file = '../../../score_models/model_comparison_metrics.csv'\n",
    "\n",
    "# # 2. Calcular el reporte de clasificación estándar\n",
    "# # Usamos y_val_m y y_val_pred que están en la misma escala (0,1,2)\n",
    "# report_dict = classification_report(y_val, y_val_pred, output_dict=True, zero_division=0)\n",
    "# precision = report_dict['macro avg']['precision']\n",
    "# recall = report_dict['macro avg']['recall']\n",
    "# f1_score = report_dict['macro avg']['f1-score']\n",
    "\n",
    "\n",
    "# # 3. Calcular el reporte de cambio de tendencia\n",
    "# report = get_trend_changes_report_dict(y_val, y_val_pred)\n",
    "# trend_change_precision = report['True']['precision']\n",
    "# trend_change_recall = report['True']['recall']\n",
    "# trend_change_f1_score = report['True']['f1-score']\n",
    "\n",
    "# # 4. Organizar las nuevas métricas\n",
    "# new_metrics = {\n",
    "#     'precision': precision,\n",
    "#     'recall': recall,\n",
    "#     'f1_score': f1_score,\n",
    "#     'trend_change_precision': trend_change_precision,\n",
    "#     'trend_change_recall': trend_change_recall,\n",
    "#     'trend_change_f1_score': trend_change_f1_score\n",
    "# }\n",
    "\n",
    "# # 5. Cargar, actualizar y guardar el DataFrame de comparación\n",
    "# try:\n",
    "#     # Intentar cargar el archivo existente\n",
    "#     comparison_df = pd.read_csv(output_file, index_col='model')\n",
    "#     # Si existe, actualizar o añadir la fila para el modelo actual\n",
    "#     comparison_df.loc[model_name] = new_metrics\n",
    "# except FileNotFoundError:\n",
    "#     # Si no existe, crear un DataFrame nuevo directamente con los datos actuales\n",
    "#     comparison_df = pd.DataFrame([new_metrics], index=[model_name])\n",
    "\n",
    "# # Guardar el DataFrame actualizado en el CSV\n",
    "# comparison_df.to_csv(output_file, index_label='model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_venv2 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
